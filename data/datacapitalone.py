# -*- coding: utf-8 -*-
"""DataCapitalOne.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WRI-_SvucPT9mtf69NBD9voQ3-jZx3Zn
"""



import pandas as pd
import requests
import json
import time
from datetime import datetime, timedelta
import numpy as np
import warnings
warnings.filterwarnings('ignore')

class IndianAgriDataFetcher:
    """
    Comprehensive tool to fetch and integrate Indian agricultural data
    Weather + Crop + Location + Soil combination
    """

    def __init__(self):
        self.base_urls = {
            'govt_open_data': 'https://api.data.gov.in/resource/',
            'weather_api': 'https://api.openweathermap.org/data/2.5/',
            'icrisat_base': 'https://data.icrisat.org/dld/',
        }

        # Indian states and major agricultural districts
        self.major_agri_districts = {
            'Punjab': ['Ludhiana', 'Amritsar', 'Patiala', 'Sangrur'],
            'Haryana': ['Karnal', 'Ambala', 'Hisar', 'Sirsa'],
            'Uttar Pradesh': ['Meerut', 'Saharanpur', 'Muzaffarnagar', 'Aligarh'],
            'Rajasthan': ['Ganganagar', 'Hanumangarh', 'Bikaner', 'Jodhpur'],
            'Maharashtra': ['Nashik', 'Pune', 'Ahmednagar', 'Solapur'],
            'Gujarat': ['Ahmedabad', 'Vadodara', 'Surat', 'Rajkot'],
            'Madhya Pradesh': ['Indore', 'Bhopal', 'Jabalpur', 'Gwalior'],
            'Karnataka': ['Bangalore Rural', 'Mysore', 'Mandya', 'Hassan'],
            'Tamil Nadu': ['Coimbatore', 'Salem', 'Erode', 'Thanjavur'],
            'Andhra Pradesh': ['Guntur', 'Krishna', 'West Godavari', 'East Godavari']
        }

        # Agro-climatic zones mapping
        self.agro_zones = {
            1: "Western Himalayan Region",
            2: "Eastern Himalayan Region",
            3: "Lower Gangetic Plains Region",
            4: "Middle Gangetic Plains Region",
            5: "Upper Gangetic Plains Region",
            6: "Trans-Gangetic Plains Region",
            7: "Eastern Plateau and Hills Region",
            8: "Central Plateau and Hills Region",
            9: "Western Plateau and Hills Region",
            10: "Southern Plateau and Hills Region",
            11: "East Coast Plains and Hills Region",
            12: "West Coast Plains and Ghats Region",
            13: "Gujarat Plains and Hills Region",
            14: "Western Dry Region",
            15: "The Island Region"
        }

        # Major crops by season
        self.crops_by_season = {
            'kharif': ['Rice', 'Cotton', 'Sugarcane', 'Maize', 'Bajra', 'Jowar'],
            'rabi': ['Wheat', 'Barley', 'Gram', 'Peas', 'Mustard', 'Linseed'],
            'zaid': ['Fodder', 'Watermelon', 'Cucumber', 'Bitter Gourd']
        }

    def fetch_government_crop_data(self, api_key=None, limit=1000):
        """
        Fetch crop production data from Indian Government Open Data API
        """
        print("Fetching Government Crop Production Data...")

        # Sample datasets (you'll need to register for API key at data.gov.in)
        datasets = [
            'district-wise-season-wise-crop-production-statistics-information-system-desi',
            'area-and-production-of-horticulture-crops-all-india'
        ]

        all_data = []

        for dataset in datasets:
            try:
                url = f"{self.base_urls['govt_open_data']}{dataset}"
                params = {
                    'api-key': api_key or 'YOUR_API_KEY_HERE',
                    'format': 'json',
                    'limit': limit
                }

                response = requests.get(url, params=params, timeout=30)
                if response.status_code == 200:
                    data = response.json()
                    all_data.extend(data.get('records', []))
                    print(f"‚úì Fetched {len(data.get('records', []))} records from {dataset}")
                else:
                    print(f"‚ö† Failed to fetch {dataset}: Status {response.status_code}")

                time.sleep(1)  # Rate limiting

            except Exception as e:
                print(f"‚ö† Error fetching {dataset}: {str(e)}")

        return pd.DataFrame(all_data) if all_data else self._create_sample_crop_data()

    def _create_sample_crop_data(self):
        """Create sample crop data when API is not available"""
        print("Creating sample crop production data...")

        sample_data = []
        for state, districts in self.major_agri_districts.items():
            for district in districts:
                for crop in ['Rice', 'Wheat', 'Cotton', 'Sugarcane']:
                    sample_data.append({
                        'State': state,
                        'District': district,
                        'Crop': crop,
                        'Season': 'Kharif' if crop in ['Rice', 'Cotton'] else 'Rabi',
                        'Area_hectares': np.random.uniform(10000, 100000),
                        'Production_tonnes': np.random.uniform(20000, 200000),
                        'Yield_kg_per_hectare': np.random.uniform(1000, 4000),
                        'Year': 2023
                    })

        return pd.DataFrame(sample_data)

    def fetch_weather_data(self, weather_api_key=None):
        """
        Fetch weather data for major agricultural regions
        """
        print("Fetching Weather Data...")

        # Major agricultural cities coordinates
        cities_coords = {
            'Ludhiana': (30.9, 75.85),
            'Karnal': (29.69, 76.99),
            'Meerut': (28.98, 77.71),
            'Nashik': (19.99, 73.79),
            'Indore': (22.72, 75.86),
            'Coimbatore': (11.02, 76.97),
            'Guntur': (16.31, 80.45),
            'Rajkot': (22.31, 70.80)
        }

        weather_data = []

        for city, (lat, lon) in cities_coords.items():
            try:
                if weather_api_key:
                    # Current weather
                    url = f"{self.base_urls['weather_api']}weather"
                    params = {
                        'lat': lat,
                        'lon': lon,
                        'appid': weather_api_key,
                        'units': 'metric'
                    }

                    response = requests.get(url, params=params, timeout=30)
                    if response.status_code == 200:
                        data = response.json()
                        weather_data.append({
                            'City': city,
                            'Latitude': lat,
                            'Longitude': lon,
                            'Temperature_C': data.get('main', {}).get('temp', 0),
                            'Humidity_percent': data.get('main', {}).get('humidity', 0),
                            'Pressure_hPa': data.get('main', {}).get('pressure', 0),
                            'Weather': data.get('weather', [{}])[0].get('description', ''),
                            'Date': datetime.now().strftime('%Y-%m-%d')
                        })

                    time.sleep(0.5)  # Rate limiting

            except Exception as e:
                print(f"‚ö† Error fetching weather for {city}: {str(e)}")

        # Create sample data if API fails
        if not weather_data:
            weather_data = self._create_sample_weather_data(cities_coords)

        return pd.DataFrame(weather_data)

    def _create_sample_weather_data(self, cities_coords):
        """Create sample weather data"""
        sample_weather = []
        for city, (lat, lon) in cities_coords.items():
            sample_weather.append({
                'City': city,
                'Latitude': lat,
                'Longitude': lon,
                'Temperature_C': np.random.uniform(15, 35),
                'Humidity_percent': np.random.uniform(40, 90),
                'Pressure_hPa': np.random.uniform(1000, 1020),
                'Weather': np.random.choice(['Clear', 'Cloudy', 'Rain', 'Partly Cloudy']),
                'Annual_Rainfall_mm': np.random.uniform(400, 1200),
                'Date': datetime.now().strftime('%Y-%m-%d')
            })
        return sample_weather

    def create_soil_data(self):
        """
        Create comprehensive soil data for different regions
        """
        print("Creating Soil Classification Data...")

        # Major soil types in India with characteristics
        soil_types = {
            'Alluvial': {'pH': (6.0, 8.5), 'organic_matter': (0.5, 2.0), 'suitable_crops': ['Rice', 'Wheat', 'Sugarcane']},
            'Black (Regur)': {'pH': (6.5, 8.5), 'organic_matter': (0.5, 1.5), 'suitable_crops': ['Cotton', 'Wheat', 'Jowar']},
            'Red': {'pH': (5.5, 8.0), 'organic_matter': (0.3, 1.0), 'suitable_crops': ['Rice', 'Ragi', 'Groundnut']},
            'Laterite': {'pH': (5.0, 6.5), 'organic_matter': (0.2, 0.8), 'suitable_crops': ['Rice', 'Ragi', 'Cashew']},
            'Desert': {'pH': (7.0, 9.0), 'organic_matter': (0.1, 0.5), 'suitable_crops': ['Bajra', 'Moth', 'Guar']},
            'Mountain': {'pH': (5.5, 7.5), 'organic_matter': (1.0, 3.0), 'suitable_crops': ['Wheat', 'Barley', 'Potato']}
        }

        soil_data = []
        for state, districts in self.major_agri_districts.items():
            for district in districts:
                # Assign soil type based on region
                if state in ['Punjab', 'Haryana', 'UP']:
                    primary_soil = 'Alluvial'
                elif state in ['Maharashtra', 'Gujarat', 'MP']:
                    primary_soil = 'Black (Regur)'
                elif state in ['Karnataka', 'Tamil Nadu', 'AP']:
                    primary_soil = 'Red'
                elif state == 'Rajasthan':
                    primary_soil = 'Desert'
                else:
                    primary_soil = np.random.choice(list(soil_types.keys()))

                soil_info = soil_types[primary_soil]

                soil_data.append({
                    'State': state,
                    'District': district,
                    'Primary_Soil_Type': primary_soil,
                    'pH_Range': f"{soil_info['pH'][0]}-{soil_info['pH'][1]}",
                    'Organic_Matter_Percent': np.random.uniform(*soil_info['organic_matter']),
                    'Suitable_Crops': ', '.join(soil_info['suitable_crops']),
                    'Nitrogen_Level': np.random.choice(['Low', 'Medium', 'High']),
                    'Phosphorus_Level': np.random.choice(['Low', 'Medium', 'High']),
                    'Potassium_Level': np.random.choice(['Low', 'Medium', 'High']),
                    'Water_Holding_Capacity': np.random.choice(['Poor', 'Fair', 'Good', 'Excellent'])
                })

        return pd.DataFrame(soil_data)

    def create_location_mapping(self):
        """
        Create comprehensive location data with agro-climatic zones
        """
        print("Creating Location and Agro-climatic Zone Mapping...")

        location_data = []

        zone_mapping = {
            'Punjab': 6, 'Haryana': 6, 'Uttar Pradesh': 5,
            'Rajasthan': 14, 'Maharashtra': 9, 'Gujarat': 13,
            'Madhya Pradesh': 8, 'Karnataka': 10, 'Tamil Nadu': 11,
            'Andhra Pradesh': 11
        }

        for state, districts in self.major_agri_districts.items():
            zone_id = zone_mapping.get(state, 8)
            for district in districts:
                location_data.append({
                    'State': state,
                    'District': district,
                    'Agro_Climatic_Zone_ID': zone_id,
                    'Agro_Climatic_Zone_Name': self.agro_zones[zone_id],
                    'Latitude': np.random.uniform(8, 35),  # India's lat range
                    'Longitude': np.random.uniform(68, 97),  # India's long range
                    'Altitude_meters': np.random.uniform(0, 2000),
                    'Growing_Season_Days': np.random.uniform(120, 300),
                    'Major_Season': np.random.choice(['Kharif', 'Rabi', 'Both'])
                })

        return pd.DataFrame(location_data)

    def integrate_all_data(self, govt_api_key=None, weather_api_key=None):
        """
        Master function to fetch and integrate all agricultural data
        """
        print("üåæ Starting Comprehensive Agricultural Data Integration...")
        print("=" * 60)

        # Fetch all datasets
        crop_df = self.fetch_government_crop_data(govt_api_key)
        weather_df = self.fetch_weather_data(weather_api_key)
        soil_df = self.create_soil_data()
        location_df = self.create_location_mapping()

        print("\nüìä Dataset Summary:")
        print(f"Crop Data: {len(crop_df)} records")
        print(f"Weather Data: {len(weather_df)} records")
        print(f"Soil Data: {len(soil_df)} records")
        print(f"Location Data: {len(location_df)} records")

        # Create comprehensive integrated dataset
        print("\nüîó Integrating datasets...")

        # Start with crop data as base
        integrated_df = crop_df.copy()

        # Add location and agro-climatic zone info
        integrated_df = integrated_df.merge(
            location_df[['State', 'District', 'Agro_Climatic_Zone_ID',
                        'Agro_Climatic_Zone_Name', 'Major_Season']],
            on=['State', 'District'],
            how='left'
        )

        # Add soil information
        integrated_df = integrated_df.merge(
            soil_df[['State', 'District', 'Primary_Soil_Type', 'pH_Range',
                    'Organic_Matter_Percent', 'Water_Holding_Capacity']],
            on=['State', 'District'],
            how='left'
        )

        # Add weather data (simplified - you might want district-level weather)
        # For now, we'll map cities to nearby districts
        city_to_district = {
            'Ludhiana': 'Ludhiana', 'Karnal': 'Karnal', 'Meerut': 'Meerut',
            'Nashik': 'Nashik', 'Indore': 'Indore', 'Coimbatore': 'Coimbatore',
            'Guntur': 'Guntur', 'Rajkot': 'Rajkot'
        }

        weather_mapped = weather_df.copy()
        weather_mapped['District'] = weather_mapped['City'].map(city_to_district)
        weather_mapped = weather_mapped.dropna(subset=['District'])

        integrated_df = integrated_df.merge(
            weather_mapped[['District', 'Temperature_C', 'Humidity_percent',
                          'Annual_Rainfall_mm']],
            on='District',
            how='left'
        )

        print(f"‚úÖ Integration Complete! Final dataset: {len(integrated_df)} records")

        return {
            'integrated': integrated_df,
            'crop': crop_df,
            'weather': weather_df,
            'soil': soil_df,
            'location': location_df
        }

    def analyze_data(self, datasets):
        """
        Perform basic analysis on integrated data
        """
        print("\nüìà Performing Data Analysis...")

        df = datasets['integrated']

        analysis = {
            'summary_stats': df.describe(),
            'crop_by_state': df.groupby('State')['Production_tonnes'].sum().sort_values(ascending=False),
            'yield_by_soil': df.groupby('Primary_Soil_Type')['Yield_kg_per_hectare'].mean(),
            'production_by_zone': df.groupby('Agro_Climatic_Zone_Name')['Production_tonnes'].sum(),
            'top_producing_districts': df.groupby('District')['Production_tonnes'].sum().sort_values(ascending=False).head(10)
        }

        print("üèÜ Top 5 Producing States:")
        print(analysis['crop_by_state'].head())

        print("\nüå°Ô∏è Average Yield by Soil Type:")
        print(analysis['yield_by_soil'])

        return analysis

    def save_data(self, datasets, filename_prefix="indian_agriculture"):
        """
        Save all datasets to CSV files
        """
        print(f"\nüíæ Saving datasets with prefix '{filename_prefix}'...")

        for name, df in datasets.items():
            filename = f"{filename_prefix}_{name}_data.csv"
            df.to_csv(filename, index=False)
            print(f"‚úÖ Saved {filename} ({len(df)} records)")

# Usage Example
def main():
    """
    Main execution function
    """
    print("üöÄ Indian Agricultural Data Integration Tool")
    print("=" * 50)

    # Initialize the fetcher
    fetcher = IndianAgriDataFetcher()

    # Get integrated data
    # Note: Replace with your actual API keys
    datasets = fetcher.integrate_all_data(
        govt_api_key="YOUR_GOV_API_KEY",  # Get from data.gov.in
        weather_api_key="YOUR_WEATHER_API_KEY"  # Get from openweathermap.org
    )

    # Analyze the data
    analysis = fetcher.analyze_data(datasets)

    # Save to files
    fetcher.save_data(datasets)

    print("\nüéâ Complete! Check the generated CSV files for your integrated agricultural data.")
    print("\nüîß To get real data, sign up for API keys at:")
    print("   ‚Ä¢ Government Data: https://data.gov.in/")
    print("   ‚Ä¢ Weather Data: https://openweathermap.org/api")
    print("   ‚Ä¢ ICRISAT Data: https://data.icrisat.org/")

if __name__ == "__main__":
    main()